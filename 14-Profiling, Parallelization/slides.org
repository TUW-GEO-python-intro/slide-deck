#+OPTIONS: reveal_center:t reveal_control:t reveal_height:-1
#+OPTIONS: reveal_history:nil reveal_keyboard:t reveal_mathjax:nil
#+OPTIONS: reveal_overview:t reveal_progress:t
#+OPTIONS: reveal_rolling_links:nil reveal_slide_number:t
#+OPTIONS: reveal_title_slide:t reveal_width:-1
#+options: toc:nil ^:nil num:nil
#+REVEAL_MARGIN: -1
#+REVEAL_MIN_SCALE: -1
#+REVEAL_MAX_SCALE: -1
#+REVEAL_ROOT: ../reveal.js
#+REVEAL_TRANS: default
#+REVEAL_SPEED: default
#+REVEAL_THEME: black
#+REVEAL_EXTRA_CSS: ../code_formatting.css
#+REVEAL_EXTRA_JS: 
#+REVEAL_HLEVEL: 1
#+REVEAL_TITLE_SLIDE_TEMPLATE: <h1>%t</h1> <h2>%a</h2> <h2>%e</h2> <h2>%d</h2>
#+REVEAL_TITLE_SLIDE_BACKGROUND:
#+REVEAL_TITLE_SLIDE_BACKGROUND_SIZE:
#+REVEAL_TITLE_SLIDE_BACKGROUND_REPEAT:
#+REVEAL_TITLE_SLIDE_BACKGROUND_TRANSITION:
#+REVEAL_MATHJAX_URL: http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML
#+REVEAL_PREAMBLE:
#+REVEAL_HEAD_PREAMBLE:
#+REVEAL_POSTAMBLE:
#+REVEAL_MULTIPLEX_ID:
#+REVEAL_MULTIPLEX_SECRET:
#+REVEAL_MULTIPLEX_URL:
#+REVEAL_MULTIPLEX_SOCKETIO_URL:
#+REVEAL_PLUGINS:
#+LOCAL_VARIABLES:
#+eval: (setq-local org-babel-default-header-args:python '((:tangle . "lecture7.py")))
#+End:

#+AUTHOR: Christoph Paulik
#+email: 
#+Title: Profiling, Optimization, Parallelization

* Optimization
#+BEGIN_QUOTE
We should forget about small efficiencies, say about 97% of the time: premature
optimization is the root of all evil. 

-- Donald Knuth
#+END_QUOTE

The problem with premature optimization is that you never know in advance where
the bottlenecks will be.
 
** When to optimize

- Make it work.
- Make it right
- Make everything work.
- Make everything right.
- Profile Before Optimizing.
- Make it fast. You maintained unit tests, right? Then you can refactor the code
  mercilessly in order to improve the performance.

[[http://c2.com/cgi/wiki?GuillermoSchwarz][Guillermo Schwarz]]

** What is generally slow in Python
- CPU bound tasks
- e.g. Nested for loops over large arrays
- But this does not mean that this is the reason why your program is slow
- Can be quite surprising at times

** Amdahl's law
A parallelized program can only be as fast as the slowest single threaded piece
of code.

#+CAPTION: Illustration of Amdahl's law from [[http://www.ibm.com/developerworks/library/l-cluster1/][IBM]]
#+ATTR_HTML: :width 60% :style background: white
[[./amdahl_law.gif]]

* Profiling
- Built in Python profiler can be called from command line or from Python itself
  or inside a IPython Notebook.
  #+BEGIN_SRC sh
  python -m cProfile -o <output> <script-name> <options>
  #+END_SRC
- Viewing profile
  #+BEGIN_SRC sh
  python –m pstats <output>
  runsnake <output>
  #+END_SRC
[[http://www.vrplumber.com/programming/runsnakerun/][  Runsnakerun]] requires wxpython – not portable
** 
#+CAPTION: Runsnake interface
#+ATTR_HTML: :width 90%
[[./runsnake.png]]
** Line profiler
- =@profile= decorator for functions that we want to look at
#+BEGIN_SRC sh
kernprof –l –o <outputfilename> <script-name> <options>
python –m line_profiler <outputfilename>
#+END_SRC
** More information about profiling
- [[http://docs.python.org/2/library/profile.html][Python Profilers]]
- [[http://pythonhosted.org/line_profiler/][Line Profiler]] 
- [[http://www.huyng.com/posts/python-performance-analysis/][Tutorial]]
- [[http://stefaanlippens.net/python_profiling_with_pstats_interactive_mode][Pstats]]
* Improving performance
Now that you have found the slow part, what to do?
- Can it be done in vectorized form? – numpy? – =no!=
- Are there other packages or existing libraries that do it? – =no!=
- Did you do it in an inefficient way? – =no!=
- Is it CPU bound and not I/O or memory bound? – =yes!=
 
If those are you answers:
- [[http://cython.org][Cython]] is a good way to go if you do not know C or C++.
- [[http://numba.pydata.org/][Numba]] should be able to do it automatically. (use Anaconda)
** Cython
- Cython gives you the combined power of Python and C to let you
  - write Python code that calls back and forth from and to C or C++ code
    natively at any point.
  - easily tune readable Python code into plain C performance by adding static
    type declarations. – different ways, we’ll focus on one.
  - [[https://github.com/cython/cython/wiki/InstallingOnWindows][Windows install instructions]]
*** Example
#+BEGIN_SRC python
  def f(x):
      return x ** 2 - x

  def integrate_f(a, b, N):
      s = 0
      dx = (b - a / N)
      for i in range(N):
          s += f(a + i * dx)
      return s * dx
#+END_SRC

*** Cython
#+BEGIN_SRC python
  def f(double x):
      return x ** 2 - x

  def integrate_f(double a, double b, int N):
      cdef int i
      cdef double s, dx
      s = 0
      dx = (b - a / N)
      for i in range(N):
          s += f(a + i * dx)
      return s * dx
#+END_SRC

*** Building Cython code
- save it in a =.pyx= file
- use =pyximport= instead of regular import
- run the =cython= command line program and then compile the =.c= file manually
- use IPython Notebook

[[http://docs.cython.org/src/quickstart/build.html#building-cython-code][More details in the documentation]]
* Example
- open =profiling.ipynb=
- profiling
- find slow part
- make it faster using cython
- IPython parallelization
